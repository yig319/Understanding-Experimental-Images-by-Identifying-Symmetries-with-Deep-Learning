{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/home/yichen/anaconda3/envs/symmetry/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from dl_utils.utils.dataset import viz_dataloader, split_train_valid, hdf5_dataset\n",
    "from dl_utils.training.build_model import fpn_resnet50_classification\n",
    "from dl_utils.training.trainer import Trainer, accuracy\n",
    "from dl_utils.packed_functions import benchmark_task\n",
    "\n",
    "ds_path_info = {'imagenet': '../../datasets/imagenet_v5_rot_10m_fix_vector.h5',\n",
    "                'noise': '../../datasets/noise_v5_rot_1m_fix_vector.h5',\n",
    "                'atom': '../../datasets/atom_v5_rot_1m_fix_vector.h5',\n",
    "                'viz_dataloader': False}\n",
    "\n",
    "training_specs = {'batch_size': 1800, \n",
    "                  'num_workers': 12, \n",
    "                  'device_ids': [4,5,6], \n",
    "                  'shuffle': True,\n",
    "                  'learning_rate': 1e-3,\n",
    "                  'validation_times': 200,\n",
    "                  'training_image_count': 10000000*20, # 20 epochs of 10 million images of full imagenet dataset\n",
    "                  'efficient_print': True,\n",
    "                  'model_path': '../../models/FPN/',\n",
    "}\n",
    "\n",
    "\n",
    "config = {'loss_func': 'CrossEntropyLoss', # nn.MSELoss()\n",
    "          'optimizer': 'Adam',\n",
    "          'scheduler': 'OneCycleLR'}\n",
    "    \n",
    "wandb_specs = {'config': config,\n",
    "                'project': 'Understanding-Experimental-Images-by-Identifying-Symmetries-with-Deep-Learning',\n",
    "                'entity': 'yig319',\n",
    "                'group': 'benchmark-latest',\n",
    "                'save_code': True,\n",
    "                'resume': 'allow'}\n",
    "\n",
    "model = fpn_resnet50_classification(in_channels=3, n_classes=17)\n",
    "task_name = '06022025-FPN-dataset_v5_size-10m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full size dataset - 10 million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'06022025-FPN-dataset_v5_size-10m-10m'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_name + '-10m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myig319\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/home/yichen/Understanding-Experimental-Images-by-Identifying-Symmetries-with-Deep-Learning/notebooks/benchmark/wandb/run-20250604_110513-06022025-FPN-dataset_v5_size-10m-dstaset_size=10000000</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/yig319/Understanding-Experimental-Images-by-Identifying-Symmetries-with-Deep-Learning/runs/06022025-FPN-dataset_v5_size-10m-dstaset_size%3D10000000' target=\"_blank\">06022025-FPN-dataset_v5_size-10m-dstaset_size=10000000</a></strong> to <a href='https://wandb.ai/yig319/Understanding-Experimental-Images-by-Identifying-Symmetries-with-Deep-Learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yig319/Understanding-Experimental-Images-by-Identifying-Symmetries-with-Deep-Learning' target=\"_blank\">https://wandb.ai/yig319/Understanding-Experimental-Images-by-Identifying-Symmetries-with-Deep-Learning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yig319/Understanding-Experimental-Images-by-Identifying-Symmetries-with-Deep-Learning/runs/06022025-FPN-dataset_v5_size-10m-dstaset_size%3D10000000' target=\"_blank\">https://wandb.ai/yig319/Understanding-Experimental-Images-by-Identifying-Symmetries-with-Deep-Learning/runs/06022025-FPN-dataset_v5_size-10m-dstaset_size%3D10000000</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "Epoch: 10/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|                                                                                   | 0/4522 [00:00<?, ?it/s]/scratch/home/yichen/Understanding-Experimental-Images-by-Identifying-Symmetries-with-Deep-Learning/src/dl_utils/training/build_model.py:317: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n",
      "  return F.upsample(x, size=(H,W), mode='bilinear') + y\n",
      "Train: 100%|██████████████████████████████████████████████████████████████████████| 4522/4522 [2:06:32<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.0378, train_accuracy: 98.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 1131/1131 [21:00<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss: 0.0379, valid_accuracy: 98.61%\n",
      "Model saved at epoch 9\n",
      "Saved new best model at epoch 9 with valid dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid: 100%|██████████████████████████████████████████████████████████████████████████| 557/557 [10:30<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise_loss: 0.1060, noise_accuracy: 96.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid:   1%|▋                                                                           | 5/557 [00:11<15:08,  1.65s/it]"
     ]
    }
   ],
   "source": [
    "training_specs['ds_size'] = 10000000\n",
    "training_specs['folder_name'] = task_name + '-10m'\n",
    "\n",
    "model.load_state_dict(torch.load('../../models/FPN/06022025-FPN-dataset_v5_size-10m-10m/epoch_9.pth', weights_only=True, map_location=torch.device('cpu')))\n",
    "training_specs['epoch_start'] = 9\n",
    "model, history = benchmark_task(task_name, model, training_specs=training_specs, ds_path_info=ds_path_info, wandb_specs=wandb_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1K training dataset size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_specs['ds_size'] = 1000\n",
    "model, history = benchmark_task(task_name, model, training_specs=training_specs, ds_path_info=ds_path_info, wandb_specs=wandb_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_specs['ds_size'] = 5000\n",
    "model, history = benchmark_task(task_name, model, training_specs=training_specs, ds_path_info=ds_path_info, wandb_specs=wandb_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10K dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_specs['ds_size'] = 10000\n",
    "model, history = benchmark_task(task_name, model, training_specs=training_specs, ds_path_info=ds_path_info, wandb_specs=wandb_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100K dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_specs['ds_size'] = 100000\n",
    "model, history = benchmark_task(task_name, model, training_specs=training_specs, ds_path_info=ds_path_info, wandb_specs=wandb_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 500K dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_specs['ds_size'] = 500000\n",
    "model, history = benchmark_task(task_name, model, training_specs=training_specs, ds_path_info=ds_path_info, wandb_specs=wandb_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 million dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_specs['ds_size'] = 1000000\n",
    "model, history = benchmark_task(task_name, model, training_specs=training_specs, ds_path_info=ds_path_info, wandb_specs=wandb_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 million dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_specs['ds_size'] = 2000000\n",
    "model, history = benchmark_task(task_name, model, training_specs=training_specs, ds_path_info=ds_path_info, wandb_specs=wandb_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 million dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_specs['ds_size'] = 5000000\n",
    "model, history = benchmark_task(task_name, model, training_specs=training_specs, ds_path_info=ds_path_info, wandb_specs=wandb_specs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
